{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "tested-meditation",
   "metadata": {},
   "source": [
    "I am taking a very famous data set from THE MNIST DATABASE (of handwritten digits), available at http://yann.lecun.com/exdb/mnist/. This was because I wanted to do some image classification for my project; this is a grey-scale data set. However the files are non-standard and require their own numpy package to import.\n",
    "\n",
    "The files were already set up as a training set of 60,000 images with a corresponding file of labels and a 10,000 image set of testing data (again, with a labels file). The handwritten digits run from 0 to 9, so I have 10 categories. I will use binary encoding so that we only need 4 outputs. Dr. Jakob Streipel helped me write the bits2int and int2bits functions.\n",
    "\n",
    "No need to sort data because it's already in the two sets.\n",
    "\n",
    "Importing the data from the files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "minute-leone",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import *\n",
    "import csv\n",
    "from scipy.optimize import fmin_bfgs,minimize\n",
    "import idx2numpy\n",
    "import time\n",
    "\n",
    "#global parameters\n",
    "regParam = 0.03 #use in cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "included-reason",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LReLU, optional to leave as ReLU by passing esp=0 \n",
    "def lrelu(x,b=1,esp=0.01):\n",
    "    y=[]\n",
    "    for xi in x:\n",
    "        if xi<0:\n",
    "            y.append(esp*xi)\n",
    "        else:\n",
    "            y.append(b*xi)\n",
    "    return array(y)\n",
    "def lrelu_prime(x,b=1,esp=0.01):\n",
    "    y=[]\n",
    "    for xi in x:\n",
    "        if xi<0:\n",
    "            y.append(esp)\n",
    "        else:\n",
    "            y.append(b)\n",
    "    return array(y)\n",
    "#x is input vector, W is weight estimation (use random entries between 0 and 1 for first estimate, call N somewhere)\n",
    "def feed_forward(x,W):\n",
    "    W0 = array(W[:k*m]).reshape((k,m))\n",
    "    b0 = W[k*m:k*m+k]\n",
    "    W1 = array(W[(m+1)*k:(m+1)*k+n*k]).reshape((n,k))\n",
    "    b1 = W[(m+1)*k+n*k:]\n",
    "    z1 = dot(W0,x)+b0\n",
    "    z2 = dot(W1,a1(z1))+b1\n",
    "    return a2(z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "coral-springfield",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------The rest of the functions we should need are in here----------------------------------\n",
    "#many of which have been hybrid-ed with Dr. COo\n",
    "#accepts a column vector argument, returns mean and l2 norm of vector\n",
    "def normalize(col): \n",
    "    l2norm = sqrt(sum((col-mean(col))*(col-mean(col)))/len(col))\n",
    "    return mean(col),l2norm\n",
    "\n",
    "#accepts no arguments, returns array of mean values for data & array of norm values\n",
    "def normalize_cols(inMat):\n",
    "    means=[]\n",
    "    norms=[]\n",
    "    for i in range(m):\n",
    "        mn,nrm=normalize(inMat[:,i])\n",
    "        means.append(mn)\n",
    "        norms.append(nrm)\n",
    "    meanValues=array(means)\n",
    "    normValues=array(norms)\n",
    "    return meanValues,normValues #returns mean and norm values of each column as arrays\n",
    "\n",
    "#accepts a matrix, returns the normalized matrix\n",
    "def normalizeByTrain(inMat):\n",
    "    meanVals,normVals = normalize_cols(inMat)\n",
    "    #print(normVals)\n",
    "    normedMat=inMat*0.0\n",
    "    for i in range(len(normVals)):\n",
    "         if normVals[i] == 0:\n",
    "            normVals[i] = 1\n",
    "    for k in range(len(inMat[:,0])): #for row k,\n",
    "        normedMat[k]=(inMat[k]-meanVals)/normVals #set the normalized row to the initial row - row of mean values\n",
    "    return normedMat\n",
    "\n",
    "#accepts input matrices X and Y and vector W\n",
    "def ensemble_cost(W,X,Y):\n",
    "    C = 0.0\n",
    "    for i in range(len(X[0,:])):\n",
    "        x=X[i,:]\n",
    "        y=Y[i,:]\n",
    "        C += 0.5*(dot(feed_forward(x,W)-y,feed_forward(x,W)-y)+regParam*0.5*linalg.norm(W)**2)\n",
    "    return C\n",
    "\n",
    "#Dr. Cooper's logistic function & it's derivative below + his other functions b/c I think they'll work more reliably\n",
    "def S(X):\n",
    "    X = X*(abs(X)<10)+10.*(X>=10)-10.*(X<=-10)\n",
    "    return 1./(1+exp(-X))\n",
    "\n",
    "def SPrime(X):\n",
    "    X = X*(abs(X)<10)+10.*(X>=10)-10.*(X<=-10)\n",
    "    ex = exp(-X)\n",
    "    return ex/((1.+ex)*(1.+ex))\n",
    "\n",
    "def relu(x,epsilon=0.0):\n",
    "    return x*(x>0)+epsilon*x*(x<=0)\n",
    "\n",
    "def reluPrime(x,epsilon=0.0):\n",
    "    return (x>0)+epsilon*(x<=0)\n",
    "\n",
    "def selu(x,lamda=1,alpha=1):\n",
    "    return lamda*( x*(x>0)+alpha*(exp(x)-1)*(x<=0))\n",
    "\n",
    "def seluPrime(x,lamda=1,alpha=1):\n",
    "    return lamda*((x>0)+alpha*exp(x)*(x<=0))\n",
    "\n",
    "#accepts input vector x, output vector out, and big W vector, returns a (regularized) gradient for one row\n",
    "def gradient(x,out,W):#<----borrowed\n",
    "    W0 = array(W[:nW0]).reshape((k,m))\n",
    "    W1 = array(W[nW0+k:-n]).reshape((n,k))\n",
    "    grad = W*0.0\n",
    "    # Get a(z_2)\n",
    "    z1 = dot(W0,x)+W[nW0:nW0+k]\n",
    "    z2 = dot(W1,a1(z1))+W[-n:]\n",
    "    forward = a2(z2)\n",
    "    err = forward-out\n",
    "    # gradient for b_1 bias weights\n",
    "    finalLayerDeriv = a2p(z2)*err\n",
    "    grad[-n:] = finalLayerDeriv+0.\n",
    "    # gradient for W_1 weights\n",
    "    grad[(nW0+k):-n] = outer(finalLayerDeriv,a1(z1)).flatten()\n",
    "    # gradient for b_0 bias weights\n",
    "    firstLayerDeriv = finalLayerDeriv.dot(W1)*a1p(z1)\n",
    "    grad[nW0:(nW0+k)] = firstLayerDeriv+0.\n",
    "    # gradient for W_0 weights\n",
    "    grad[:nW0] = outer(firstLayerDeriv,x).flatten()\n",
    "    return grad+regParam*W\n",
    "\n",
    "#accepts vector W, input matrix X and output matrix Y\n",
    "def gradSum(W,X,Y):\n",
    "    grad = zeros(nVar)\n",
    "    for i in range(len(X[:,0])): #X[:,0] is a slice of all the rows in the first column\n",
    "        grad += gradient(X[i,:],Y[i,:],W)\n",
    "    return grad\n",
    "def int2bits(n,bits=4):\n",
    "    return [int(b) for b in list(format(n, \"0\"+str(bits)+\"b\"))]\n",
    "def bits2int(lst):\n",
    "    integer =0\n",
    "    for i in range(len(lst)):\n",
    "        integer += lst[i]*2**(len(lst)-i-1)\n",
    "    return integer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handed-cable",
   "metadata": {},
   "source": [
    "Here is the actual neural network code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abstract-appointment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data\n",
    "inData = idx2numpy.convert_from_file('train-images.idx')\n",
    "outData = idx2numpy.convert_from_file('train-labels.idx')\n",
    "inTestX = idx2numpy.convert_from_file('t10k-images.idx')\n",
    "inTestY = idx2numpy.convert_from_file('t10k-labels.idx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "black-rough",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10969710350036621\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tempX = []\n",
    "length,pic1,pic2 = shape(inData)\n",
    "start = time.time()\n",
    "for i in range(length):\n",
    "    tempX.append(inData[i,:,:].reshape(pic1*pic2))\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "trainX = array(tempX)\n",
    "shape(trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aging-terminology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.20551013946533203\n"
     ]
    }
   ],
   "source": [
    "n = 4 #n is the number of outputs desired\n",
    "tempY = []\n",
    "start = time.time()\n",
    "for i in range(len(outData)):\n",
    "    tempY.append(int2bits(int(outData[i]),n))#encoding trainY as binary instead of leaving it as the integer values in outData\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "trainY = array(tempY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "thermal-ecuador",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data items: 784\n",
      "Number of hidden cells: 526\n"
     ]
    }
   ],
   "source": [
    "m = len(trainX[0]) #m is the number of inputs, i.e. number of columns in first row\n",
    "k = int(2*m/3+n) #k is the number of hidden layers\n",
    "W = random.rand((m + 1)*k+(k + 1)*n) #our first estimate of our W\n",
    "print('Number of data items: {}'.format(m))\n",
    "print('Number of hidden cells: {}'.format(k))\n",
    "\n",
    "nW0 = m*k\n",
    "nW1 = k*n\n",
    "nVar = nW0+nW1+k+n\n",
    "\n",
    "#normalize the vector\n",
    "trainX = normalizeByTrain(trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "handy-visiting",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train: 581.8592481613159\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(solver='lbfgs', activation='logistic',alpha=regParam, hidden_layer_sizes=(k,), random_state=1)\n",
    "start = time.time()\n",
    "clf.fit(trainX,trainY)\n",
    "end = time.time()\n",
    "print(\"Time to train:\", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "continuing-purple",
   "metadata": {},
   "outputs": [],
   "source": [
    "tempX = []\n",
    "length,pic1,pic2 = shape(inTestX)\n",
    "for i in range(length):\n",
    "    tempX.append(inTestX[i,:,:].reshape(pic1*pic2))\n",
    "testX = array(tempX)\n",
    "shape(testX)\n",
    "inTestX = normalizeByTrain(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "apart-gather",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4 #n is the number of outputs desired\n",
    "tempY = []\n",
    "for i in range(len(inTestY)):\n",
    "    tempY.append(int2bits(int(inTestY[i]),n))#encoding trainY as binary instead of leaving it as the integer values in outData\n",
    "testY = array(tempY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "vietnamese-mailing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = clf.predict(trainX)\n",
    "clf.score(trainX,trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "coupled-monday",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8276"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = clf.predict(testX)\n",
    "clf.score(testX,testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "smoking-cycle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predic: [0 1 1 1]\n",
      "Actual: [0 1 1 1]\n",
      "Number: 7\n",
      "Predic: [0 0 1 0]\n",
      "Actual: [0 0 1 0]\n",
      "Number: 2\n",
      "Predic: [0 0 0 1]\n",
      "Actual: [0 0 0 1]\n",
      "Number: 1\n",
      "Predic: [0 0 0 0]\n",
      "Actual: [0 0 0 0]\n",
      "Number: 0\n",
      "Predic: [0 1 0 0]\n",
      "Actual: [0 1 0 0]\n",
      "Number: 4\n",
      "Predic: [0 0 0 1]\n",
      "Actual: [0 0 0 1]\n",
      "Number: 1\n",
      "Predic: [0 0 0 0]\n",
      "Actual: [0 1 0 0]\n",
      "Number: 4\n",
      "Predic: [0 0 1 1]\n",
      "Actual: [1 0 0 1]\n",
      "Number: 9\n",
      "Predic: [1 1 0 0]\n",
      "Actual: [0 1 0 1]\n",
      "Number: 5\n",
      "Predic: [1 0 0 1]\n",
      "Actual: [1 0 0 1]\n",
      "Number: 9\n",
      "Predic: [0 0 0 0]\n",
      "Actual: [0 0 0 0]\n",
      "Number: 0\n",
      "Predic: [0 1 1 0]\n",
      "Actual: [0 1 1 0]\n",
      "Number: 6\n",
      "Predic: [1 0 0 1]\n",
      "Actual: [1 0 0 1]\n",
      "Number: 9\n",
      "Predic: [0 0 0 0]\n",
      "Actual: [0 0 0 0]\n",
      "Number: 0\n",
      "Predic: [0 0 0 1]\n",
      "Actual: [0 0 0 1]\n",
      "Number: 1\n",
      "Predic: [0 1 0 1]\n",
      "Actual: [0 1 0 1]\n",
      "Number: 5\n",
      "Predic: [1 0 0 1]\n",
      "Actual: [1 0 0 1]\n",
      "Number: 9\n",
      "Predic: [0 1 1 1]\n",
      "Actual: [0 1 1 1]\n",
      "Number: 7\n",
      "Predic: [1 0 1 0]\n",
      "Actual: [0 0 1 1]\n",
      "Number: 3\n",
      "Predic: [0 1 0 0]\n",
      "Actual: [0 1 0 0]\n",
      "Number: 4\n",
      "Predic: [1 0 0 1]\n",
      "Actual: [1 0 0 1]\n",
      "Number: 9\n",
      "Predic: [0 1 1 0]\n",
      "Actual: [0 1 1 0]\n",
      "Number: 6\n",
      "Predic: [0 1 1 0]\n",
      "Actual: [0 1 1 0]\n",
      "Number: 6\n",
      "Predic: [0 1 0 1]\n",
      "Actual: [0 1 0 1]\n",
      "Number: 5\n",
      "Predic: [0 1 0 0]\n",
      "Actual: [0 1 0 0]\n",
      "Number: 4\n",
      "Predic: [0 0 0 0]\n",
      "Actual: [0 0 0 0]\n",
      "Number: 0\n",
      "Predic: [0 1 1 1]\n",
      "Actual: [0 1 1 1]\n",
      "Number: 7\n",
      "Predic: [0 1 0 0]\n",
      "Actual: [0 1 0 0]\n",
      "Number: 4\n",
      "Predic: [0 0 0 0]\n",
      "Actual: [0 0 0 0]\n",
      "Number: 0\n",
      "Predic: [0 0 0 1]\n",
      "Actual: [0 0 0 1]\n",
      "Number: 1\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    print(\"Predic:\",pred[i,:])\n",
    "    print(\"Actual:\",testY[i,:])\n",
    "    print(\"Number:\",inTestY[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arranged-oregon",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
